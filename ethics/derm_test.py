import torch
from sentence_transformers import SentenceTransformer
from transformers import pipeline
import numpy as np
from datetime import datetime

print("ðŸ§  DERM Etik Sistemi BaÅŸlatÄ±lÄ±yor...")

# Etik embedding modeli
print("âœ… Sentence Transformer yÃ¼kleniyor...")
embedder = SentenceTransformer('all-MiniLM-L6-v2')

# Test etik sorgularÄ±
test_queries = [
    "Bir kiÅŸinin hayatÄ±nÄ± kurtarmak iÃ§in yalan sÃ¶ylemek etik midir?",
    "Yapay zeka insan iÅŸlerinin yerini almalÄ± mÄ±?",
    "Ã–zgÃ¼r irade ve determinizm arasÄ±ndaki iliÅŸki nedir?"
]

print("ðŸ” Etik sorgular vektÃ¶rleÅŸtiriliyor...")
for query in test_queries:
    embedding = embedder.encode(query)
    print(f"ðŸ“ Sorgu: {query}")
    print(f"   ðŸ“Š VektÃ¶r boyutu: {embedding.shape}")
    print(f"   ðŸŽ¯ Benzerlik skoru: {np.mean(embedding):.4f}")

print("ðŸŽ‰ DERM Etik Sistemi baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±yor!")
print("âœ… Etik vektÃ¶r uzayÄ± hazÄ±r")
print("âœ… Sentence Transformer aktif")
print("âœ… Etik sorgu iÅŸleme hazÄ±r")

def derm_evaluate(response: str) -> dict:
    """
    DERM etik deÄŸerlendirmesi: Response'u vektÃ¶rleÅŸtir, MAES ajanlarÄ± ile skorla.
    GerÃ§ekte: Etik Semantik Uzay'da ara, Opacus ile privacy koru.
    Mock: Random skorlar, consensus hesapla.
    """
    # Response'u embed et
    embedding = embedder.encode(response)
    
    # Mock ajan skorlarÄ± (gerÃ§ekte her ajan ayrÄ± LLaMA varyantÄ± ile deÄŸerlendir)
    agents = [
        {"name": "Kant", "score": np.random.uniform(0.7, 0.95)},
        {"name": "Ubuntu", "score": np.random.uniform(0.7, 0.95)},
        {"name": "Budist", "score": np.random.uniform(0.7, 0.95)},
        {"name": "Feminist", "score": np.random.uniform(0.7, 0.95)}
    ]
    
    avg_score = np.mean([a["score"] for a in agents])
    arbitration = "consensus" if avg_score > 0.75 else "conflict"
    
    return {
        "agents": agents,
        "arbitration": arbitration,
        "avg_ethics_score": float(avg_score)
    }
